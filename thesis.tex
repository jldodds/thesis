\documentclass{puthesis}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{url}       % SB
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{times}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{mathpartir}
\usepackage{semantic}
\usepackage{listings}
\usepackage{lstlangcoq}
\usepackage{caption}
\usepackage{stmaryrd}
\usepackage{minted}
\renewcommand{\lstlistingname}{Figure}
\input{macros}

\lstset{language=Coq,alsoletter=_,basicstyle=\sffamily,mathescape=true,columns=fullflexible}



\author{Josiah Dodds}
\adviser{Andrew Appel}
\title{Computation Improves Interactive Symbolic Execution}
\abstract{The abstract goes here.}
\acknowledgements{Thank you very much.}
\dedication{To myself.}



\begin{document}



\chapter{Introduction}

The C programming language is one of the most commonly used languages
for writing critical software. C is often used for operating systems,
embedded systems, and cryptography, as well as countless libraries
that need to have a great performance while being usable by as many
languages and systes as possible. The world depends on more systems
every day, and a large number of those systems have C code at their core.

In general, the code we depend on works well, and there is plenty of
code that can fail without causing harm but when it fails it can be
catastrophic. Space projects that cost hundreds of millions of dollars
have failed due to software failures, radiation devices with software
flaws have overdosed cancer patients, nuclear missile detection
systems have given false positives, and millions of cars have been
recalled to fix software bugs. Those scenarios are only bugs; Far more
systems can fail when a malicious user attacks them. As an example
a brand of refrigerators was found to have been taken over to send
spam email. 

To believe that a C program will run correctly we must first believe a
number of other things. There are a number of components that we will
need to be able to \emph{trust} in order to trust our C program. We need
to fully understand the program itself, and believe that it will do
what we want it to. We also need to believe that when
the C code is translated into machine language, the generated machine
language has the same behavior as the original program. Finally we
need to believe that the machine executing the machine language is
doing the correct thing. We call the collection of things we must
trust the \emph{trusted computing base}. In general, the larger the
trusted computing base is, the harder it is to be confident that the
program is correct.

The need for trust follows a chain. It starts with the C program at
the top, the most human understandable part of the chain, and moves
down to the actual execution of the machine. In order to make the
trusted computing base as small as possible, we must maximize our
confidence in every step of the process.

Proof assistants are tools for stating theorems, and then writing and
checking proofs of those theorems. If you want to believe a pen and
paper mathematical proof you first need to understand the statement of
the proof, which is open to ambiguities based on (often unstated)
assumptions made by the writer, and then believe every single step of
the proof itself, even steps where the proof author says something
vague like ``clearly'' or ``obviously''. This can be an enormous
burden on the person that needs to understand how the proof was done;
new proofs can use new techniques that are impenetrable to anyone but
experts in the specific domain of the proof. This is a real problem,
because often the thing being proved is incredibly useful to a large
range of people even if the proof itself is difficult for them to
understand. If you want to use a pen and paper proof that you can't
understand, you must trust the process of peer review. Maybe you
noticed that the paper appeared in a good publication. This means that
some number of anonymous reviewers believed the proof. They are
probably experts, and you want the proof to be true anyways so you can
use it, so you go ahead and use their theorem for your own work.

A proof assistant, on the other hand, forces proof statements to be
written using a set of basic, well defined building blocks, making
theorem statements completely unambiguous. The proof assistant often
provides tools for building proofs. These tools write proofs using a
similar set of well-defined building blocks to the ones used for
stating the theorem. Again, these building blocks are
unambiguous. There is not building block for ``clearly'' or
``obviously'', all proofs must be fully explicit all the way down.
This means that the tools for building proofs don't need to be
trusted. All that needs to be trusted is a part of the proof assistant
that checks the proof when it is created. This is analogous to not
needing to trust the person writing a pen and paper proof, as long as
you trust the proof that they wrote. That means that the proof itself
is irrelevant to someone interested in believing the theorem. All
that is relevant is that the proof assistant successfully checked the
proof, and that the proof assistant's checker is correct. This means
that if a proof is stated and proved in a proof assistant, to believe
the proof we must trust:

\begin{enumerate}
  \item The statement of the theorem being proved, and
  \item the correctness of the checker. 
\end{enumerate}

Because the writers of proof assistants are aware of the importance of
having a small trusted computing base, they often make an effort to
make the checker as simple and minimal as possible. As small as the
checker is, it can still be difficult for an average user of the proof
assistant to believe on their own. Once again, the best place to look
in order to believe the proofs in to peer review. In this case though,
it is not a few anonymous reviewers that are looking at an individual
proof, it is the entire community that is interested in the
correctness of the proof assistant. This is an advantage of
concentrating trust. The fewer things that need to be trusted, the
more attention they can get.


A verified compiler gives a proof that if it is given a valid C
program, it will generate assembly code with the same behavior as the
C program. This proof is checked by the Coq proof assistant, meaning
that its trusted base is the Coq proof checker and the statement of
the theorem. To be able to use the theorem effectively though, we need
to be able to show that the C program will always have a valid
execution. 

The results of the verified compiler tells us that the compiler won't
change the behavior of the program, but this is only really useful to
us if our program is doing the right thing in the first place. It can
be very hard to determine what a C program is doing just by examining
the source code.  A typical C program doesn't just declare what it is
doing, it declares how it is doing it. The C language is relatively
low level meaning that a program will need more details about how the
computation is done than a higher level language. The high level of
control over the details of execution is a large part of why C
continues to be popular over 40 years after it was created. It allows
programmers to write more efficient programs, but it can make it much
harder to understand what the program is actually doing.

In order to specify what a program is doing rather than how it is
doing it we write a mathematical specification of what the program
should do. This mathematical model lacks the complexity that a real
program needs to work efficiently on a computer.  The specification is
a new link in the chain above the C source code, but I have not
described how it is attached to the rest of the chain yet. A
\emph{Program Logic} is used to prove that the result of executing the
C program meets the specification. This program logic can be written
in Coq, and proved correct using the same specification of the C
language that CompCert uses. With this proof, the chain can be
completed from specification all the way to assembly language.

The combination of the tools mentioned here gives proof that the
assembly code that the machine executes has the same behavior as an
abstract mathematical specification. To believe that the proof is
correct, all we need to trust is the mathematical specification itself
and the theorem prover's proof checker.

There is still a significant amount of work to do if you wish to prove
a program correct. First you must create an accurate specification
which can be difficult, especially for complex programs. Then the
process of proving a program meets a specification using a program
logic can be very involved. Program logics implemented in proof
assistants are often \emph{interactive}. To build a proof in an
interactive program logic, you examine a proof state and then perform
an action to manipulate that state. The action will result in a new
proof state, which you can repeatedly manipulate 
until the proof is completed.

One of the biggest problems that complex program logics run into is
that they are slow. This means that the time between giving input and
receiving a new proof state can be long. Writing a proof in a program
logic is already difficult work requiring intimate knowledge of the
program, the programming language, and the logic. Having to wait
between each step in a proof multiplies the difficulty.  This is
because proof development is often experimental in nature. The first
step is to make a good guess at a specification. If the proof gets
stuck, either the specification or the program needs to change. When
those change, the proof will need to start over from the beginning. A
slow program logic can drastically limit the number of manipulations
of the program or the specification that can be done in any given
stretch of time. If the time is long enough, it can become difficult
the person doing the proof to remember what they were working on when
they last made progress on the proof.

This thesis shows how a complex programming logic for proving the
correctness of C programs can be made significantly faster without any
noticeable impact on the proving experience. This results in a logic
that is significantly more intuitive and usable, and is a vital step
in making the program logic a widely usable tool.

Many of the parts discussed so far are existing work: The proof
assistant we have chosen to use is Coq, Leroy's CompCert \cite{} is a
C compiler implemented and proved sound in Coq, and Appel et al. have
created the Verified Software Toolchain (VST) to give a proved-correct
chain from specification language to assembly including a
specification logic and a program logic to relate the specification to
a CompCert C program.

\paragraph{Contribution}
This thesis discusses the modification of a program logic to improve
usability and speed up the application of the logic. It consists of a
number of modifications to the logic and results in a tactic for
manipulating proofs about C programs. The tactic runs at least 40x
faster than previous tactics and works on all verifiable-c non-call
assignment statements (\lstinline|x := e|), meaning it makes progress
on a single basic block at a time. The tactic is fully compatible with
previous tactics, meaning that in places where it is not usable,
existing tactics can still make progress on the proof.

\chapter{Computation in Coq}

The Coq proof assistant has a built in functional programming language
called Gallina with the ability to match inductive data-structures. The type
boolean, for example can be defined:

\begin{minted}{coq}
Inductive boolean :=
| true
| false.
\end{minted}

so \lstinline|boolean| is a type that can be constructed by either
\lstinline|true| or \lstinline|false| and when given a
\lstinline|boolean|, a function can decide which of the two it is. Now
we can look at the definition of \lstinline|True| and
\lstinline|False|, which are in the type
\lstinline|Prop| instead of \lstinline|boolean|. Prop is not an
inductively defined type in Coq, so it can't be matched
against. Instead the definitions of \lstinline|True| and \lstinline|False|
are

\begin{minted}{coq}
Inductive True : Prop := I : True.
\end{minted}
\begin{minted}{coq}
Inductive False : Prop.
\end{minted}

\noindent so if a Coq program is given something of type
\lstinline|Prop|, it has no ability to determine more information
about it, just like if it is given a polymorphic value it is unable to
determine what the type of the value is is. That doesn't mean that it
is impossible to reason about things of type \lstinline|Prop| in
Coq. Instead of using Gallina to operate on \lstinline|Prop|, Coq has
tactics, which exist almost exclusively for that reason. A tactic in
Coq is a program that manipulates a proof state while generating a
proof object recording its activity. A Coq proof state is
a goal, or a \lstinline|Prop| to be proved, along with a number of
quantified variables of any type, and a number of hypothesis of type
\lstinline|Prop|. Because tactics are used to build proofs, it must keep a
record any time it makes progress on the proof term so that when the
proof is over, the record of the proof, or the proof object, can be
checked.

This design means that tactics don't need to be sound. As long as they
result in a correct proof in the end, it doesn't really matter how
they did it. Proofs that do a large amount of proof search to do a
reasonably small amount of work in the end can perform reasonably well
in tactical proof. Unfortunately, many of the proofs that Coq's users
want to do require both a lot of proof search, and numerous operations
over the proof state to succeed. In these cases, the overhead of
keeping and modifying the proof object (which can take up substantial
amounts of memory) can lead to very slow tactic performance.

Logics such as VST's verifiable C program logic are in
\lstinline|Prop|. Logics in Prop are said to be shallowly
embedded. They use the syntax of Coq, rather than defining a logic of
their own. Some systems such as Appel's VeriSmall \cite{} are deeply
embedded, meaning they define their own syntax, along with a
denotation that gives meaning to that syntax in Coq's logic. 

Shallow and Deep embeddings have tradeoffs in two areas:

\begin{enumerate}
\item interactivity, or how convenient it is for users to interact
  with the logic, generally in the way they would expect to be able to
  interact with Coq's logic, and
\item automation, or the ability of the logic writer to provide the
  user of the logic with tools to efficiently reason about the logic.
\end{enumerate}

For interactivity, a shallow embedding will automatically get all of
the automation that Coq provides. Ltac can be used to write decision
procedures about the logic without requiring soundness proofs for
those procedures. A deep embedding, however, will be much harder to
interact with. To have meaning as a proof goal, a deep embedding will
need to be wrapped in its denotation function. At this point many of
the operations users familiar with Coq would expect will require a
significant amount of work from the creator of the logic. The main
reason for this is that in a deep embedding every operation on the
deeply embedded assertion must be proved sound with respect to the
denotation function. Take Coq's rewrite tactic as an example. In this
tactic if we have a lemma about an equality for example:

\begin{minted}{coq}
Lemma add_symm : forall a b, a + b = b + a
\end{minted}

and we wish to prove a goal 

\begin{minted}{coq}
a : nat
b : nat
c : nat
======================
a + (b + c) = a + (c + b) 
\end{minted}

we can use the tactic \lstinline|rewrite (add_sym b c); reflexivity|
to transform the left side to match the right side, and then tell Coq
that we have an equation where the two sides are syntactically
equal. We supply the arguments \lstinline|b| and \lstinline|c| to the
tactic because it is ambiguous where to rewrite the lemma, and Coq
might guess wrong unless we tell it.

Now we can create a deep embedding for nat, addition, and equality

\begin{minted}{coq}
Inductive expr' :=
| num : nat -> expr
| add : expr -> expr -> expr.

Inductive expr :=
| eq : expr' -> expr' -> expr.

Fixpoint expr'_denote e:=
match e with
| num n => n
| add e1 e2 => expr_denote e1 + expr_denote e2
end.

Definition expr_denote e :=
match e with
| eq e1 e2 => expr'_denote e1 = expr'_denote e2
end.
\end{minted} 

Then we can write a symmetry lemma

\begin{minted}{coq}
Lemma add_sym' : forall a b, 
expr'_denote (add a b) = expr'_denote (add b a)
\end{minted}

While this isn't too hard to prove, it also doesn't end up being too
useful in proving our goal:

\begin{minted}{coq}
a : expr
b : expr
c : expr
======================
expr_denote (add a (add b c)) (add a (add c b))  
\end{minted}

The lemma we wrote doesn't match the syntax of what we need to prove
so we can't use the rewrite tactic. We could unfold the definition of
\lstinline|expr_denote| and \lstinline|expr_denote'| in our goal, but
then we would lose the deep embedding. Instead, if we want this
functionality, we need to write a \emph{Coq function} that does the
rewrite and prove that function sound with respect to the denotation
function (assuming we have an equality function on our expr, which
isn't hard to write):

\begin{minted}{coq}
Fixpoint symmetry' e e1 e2 := 
match e with
| add e1' e2' => if (e1 == e1' && e2 = e2') 
                 then add e2' e1' 
                 else add (symmetry e1') 
                          (symmetry e2')
| x => x
end.

Definition symmetry e e1 e2 :=
match e with
| eq ex1 ex2 => eq (symmetry' ex1 e1 e2) (symmetry ex2 e1 e2)
end.

Lemma symmetry_func_sound : 
forall e1 e2 e,
expr_denote (e) = expr_denote (symmetry e e1 e2)
...
\end{minted}

Now we can rewrite by \lstinline|symmetry_func_sound| and simplify the definition
of symmetry in the new goal, and we will have done the same thing we
did with LTac in a single command.

Why would we ever use a deep embedding when automation is so much
work? The main reason is efficiency. While LTac does an operation and
needs to build a proof object, a proved-sound function that operates on
a deeply embedded proof goal does an operation and at the same time is
a (very small) proof object. The example above did a very small amount
of work in the symmetry function, but such a function could be an
entire decision procedure. Then we would be able to do a large
amount of work on a deeply embedded proof term while hardly generating
any proof object at all. In general, this will be substantially more
efficient than using LTac, especially as the size of the
deeply-embedded statements grows. 

Another advantage to a deeply embedded logic is that if there is a
single decision procedure for it that works all in one function, that
function can be \emph{extracted} and run in OCaml. This gives the
performance of an optimized language, with most of the assurance that
comes with having a proved-sound decision procedure in Coq.

The technique of computational reflection in Coq aims to combine the
interactivity of a shallow embedding with the efficiency of a deep
embedding by moving between the two when it is needed.

\section{Computational reflection}

Proof by reflection is the technique of using proved-sound computation
on a deep embedding to make progress in a proof. To use reflection on
a shallow embedding, there will first need to be a translation from
the shallow embedding into a deep embedding. Then a proved-sound
function can be evaluated on the deep embedding, and if it is
appropriate the denotation function can be evaluated, resulting in a
shallow embedding again.  If this is done all in a single step, the
user of a reflective tactic never needs to know that reflection is
being used. That means that the efficient, proved-sound decision
procedures that can be used on deep embeddings can essentially be used
as if they are tactics, along side all of the other tactics and LTac
automation that might be built up around a logic.

The process of translating from a shallow embedding to a deep
embedding is known as reification. Because Coq programs can't match on
shallow embeddings, reification must be performed by a
tactic. Reification leaves us with a deep embedding (or reified
expression), which allows us to use proved-sound Coq functions to
progress the proof state without large proof terms. When the deep
embedding is at a state that requires human work, the denotation
function can be carefully unfolded, or reflected, to return it to a
shallow embedding that is easy for the user to view and work with.

%graphic from prefpo 

Many shallow embeddings, including VST's logic, have parts that are
made up completely of constructors. In many program logics, for
example, the programming language will not be Coq's programming
language, but a deep embedding of the syntax of the language along
with a semantics that describes the execution of that syntax in the
state of the programming language. Because the syntax is a deep
embedding, it is possible to write Coq functions that reason about
them, and then prove those functions sound (usually with respect to
the operational semantics). This is a type of reflection that doesn't
require reification at all, making it more efficient and allowing it
to fit cleanly into the shallowly embedded program logic. One such
example in VST is the typechecker which is used to show that
expressions in the program successfully evaluate given the state
represented by the precondition.


\chapter{Typechecking C Expressions}

The CompCert operational semantics has a partial inductive relation
$\rho \vdash e\Downarrow v$ for evaluation of an ($r$-value)
expression $e$ to a value $v$ in environment $\rho$, and another
relation $\rho \vdash e\Downarrow_l v$ for the $l$-value
interpretation of an expression.  These relations are inconvenient in
program proof, as we would frequently need existential variables
$\exists v.~\rho \vdash e\Downarrow_l v$, and proofs of often trivial
side-conditions that $v$ exists. This chapter discusses why this
semantics is written in this manner and why reasoning about the
semantics by way of a program logics gives us the flexibility to do
things in a more computational manner.

\section{Type soundness of C}

A type system is sound with respect to an operational semantics if a
well typed program will never go wrong. Go wrong can mean a variety of
things depending on the goal of the type system, going wrong could be
a runtime error caused by a failed type conversion, dereferencing a
null pointer, or entering a state not described by the semantics of
the language. A type checker is typically a decision procedure that
decides if a program is well typed in a type system. A trivially sound
type system and type checker reject all programs.



It is possible to create a type system for C that accepts a reasonable
number of programs and is sound with respect to
a limited notion of ``going wrong''. It is impossible to extend this
notation to any degree of memory safety, or more usefully to extend it
to state that a program will always exhibit defined behavior.



In general, it is impossible to have a sound and typechecker
for C because the safe execution of C programs depends on dynamic
properties of the program. A C program with a division by $0$, for
example, will typecheck and then might crash on execution. The
situation might be worse than crashing too because almost all C
programs that crash are exhibiting undefined behavior. That means that
the compiler can generate whatever code it wants and still be a valid
C compiler. For an example, a valid but unlikabe C compiler could
generate code that erases your hard drive in place of code that
performs division by 0.

This was done for performance reasons. It is nice for compiler writers
to not have to worry about malformed programs and instead write
optimizations and instructions that assume that programs will behave
nicely.  As a result, individual compilers generally exhibit
reasonably consistent behavior, but there is no real requirement for
them to do so. Changing compilers or even compiler settings could lead
to massive changes in the execution of programs that perform undefined
operations. This is especially dangerous because unless a programmer
pays careful attention to the C standard (a document with over 500
pages, 13 of which are used just listing the various undefined
behaviors), they might never know that their code is exhibiting
undefined behavior until it causes a problem.


Because it is impossible to create a C type system that is sound,
decidable, and accepts a reasonable number of programs, we use a
type system that is not decidable, leaving the more difficult parts to
decide up to the user. This means that our type-checker \cite[Chapter 25]{appel14:plcc} 
\lstinline|tc_expr ($\Delta$ : tycontext) (e : expr) : tc_assert|
calculates minimal nontrivial separation-logic
assertions required for safe evaluation of expressions.  It does this
with the help of a type-context $\Delta$ that (conservatively) tracks the
initialization status of all variables; soundness of the program logic
guarantees that all initialized variables contain defined values of
the right type. Because the typechecker is a function whose
result we will use in our program logic, it is important that all of
its arguments are deeply embedded. The expression comes from a
concrete compiled program, so we know that it will be made completely
of constructors. We chose the definition of the type context to be a
computationally efficient mapping structure indexed by program
variables that will always have concrete values. This means that we
can be confident that a call to \lstinline|tc_expr| will always compute
to an assertion.

If we know that an expression will successfully evaluate, we can
eliminate the existentials connected to expression evaluation by
defining (total) functions \lstinline|eval_expr| and
\lstinline|eval_lvalue| that will give the same result as the
operational semantics relation assuming that the expression
typechecks. This means that as long as the program logic type checks
the program logic it can use \lstinline|eval_expr| where it would
generally need the less convenient $\exists v.~\rho \vdash e\Downarrow_l v$. 

Our typechecker is written in two layers: a translation from type
contexts and C expressions to \emph{syntactic} type-checking
assertions, and a denotation function from this syntax into Coq
propositions \lstinline|Prop|.  We can therefore
\emph{computationally} simplify assertions even before taking their
denotation.  Consider the expression \lstinline{3 + x}; the
precondition needed to evaluate this is 
\lstinline|True /\ initialized(_x)|. The \lstinline|True| is redundant, but if this
assertion were generated directly, no more computational progress can
be made. Instead our context $\Delta$ records that $x$ is an
initialized integer variable and computes the simplified syntactic
TC-assertion \lstinline|tc_TT|, whose denotation is \lstinline|True|.
This simplification improves performance even when using Ltac. We
further improve performance even in Ltac by using computation to
simplify our separation logic predicates.


\chapter{Canonical Forms for Assertions}

VST uses assertions to reason about programs, but what does 
it require about the form of these assertions? This chapter
discusses that, as well as how restricting the form of
assertions improve both the usability and the performance
of symbolic execution.

\section{Semi-Canonical Form}

We previously described \cite{appel14:plcc} assertions in the form
~~\lstinline{PROP $~P$ LOCAL $~Q$ SEP $~R$}.  Here each item in
\lstinline|$P$:list prop| is a pure assertion that doesn't refer to
the program state. \lstinline|$Q$: list (environ -> prop)| contains
assertions that can reason about local variables.  and 
\lstinline|$R$: list (environ -> mpred)| has spatial assertions that can reason about
both local variables and memory.  $\PROP$ folds conjunction over the
elements of $P$, $\LOCAL$ folds lifted conjunction ( 
\lstinline|`and : (environ -> Prop)-> (environ -> Prop) -> (environ -> Prop))|, and
$\SEP$ folds the separation logic \lstinline|*|, or separating
conjunction operator. $P$, $Q$, and $R$, are represented as lists
because, particularly in the case of $\SEP$, it is convenient to refer
to the $n$th conjunct. This is much easier to implement when our
assertion is restricted to a flat sequence of conjunctions.  We say
that assertions in this form are in semi-canonical form.

At the lowest level, the Verifiable C logic rules are agnostic to any
structure that the assertion might have. The rules refer to
assertions as single variables, using entailments to constrain them
rather than imposing syntactic requirements on them. The Floyd
automation system has higher level lemmas that require assertions
to be in semi-canonical form, but also guarantee that the side
conditions that result from using the rules will be in semi-canonical
form.

\subsection{Substitution in semi-canonical form}

At the Verifiable C level, there is no choice but to use a semantic
notion of substitution called \linebreak
\lstinline|subst {A: Type} (x : ident) (v:val) (P : environ -> A) : environ -> A|.
This is because we know nothing about the assertion at all, only that
it takes an environment and returns an \lstinline|mpred|. The following example
shows how \lstinline|subst| is used:

\begin{lstlisting}
$\inference[semax\_set\_forward]{}{
\Delta\vdash\triple{\later P}{~x:=e~}{\exists v.\,x=(e[v/x])\wedge P[v/x]}
}$

Axiom semax_set_forward: $~~$forall $\Delta$ ($P$: environ->mpred) ($x$: ident) ($e$: expr),
  semax $\Delta$
    (|> (local (tc_expr $\Delta$ $e$) && local (tc_temp_id id (typeof $e$) $\Delta$ $e$) && $P$))
    (Sset $x$ $e$) 
    (normal_ret_assert 
      (EX old:val, local (`eq (eval_id $x$) (subst $x$ (`old) (eval_expr $e$)))
                    && subst $x$ (`old) $P$)).
\end{lstlisting}

There are two substitutions here, used to replace any occurrences of
the variable \lstinline|x| that might have occurred in either the
precondition or the expression being assigned into \lstinline|x|. To
see why the substitution is necessary, the following example shows
what happens if we don't have substitution:

\begin{minted}{coq}
{eval_id x = 3}
   x = 4;
{eval_id x = 3 /\ eval_id x = 4}
\end{minted}

For the triple above to hold, the program would need to infinite loop
on the assignment to \lstinline|x|, which seems unlikely. Instead we
do the substitution and get:

\begin{minted}{coq}
{eval_id x = 3}
   x = 4;
{exists x_old, x_old = 3 /\ eval_id x = 4}
\end{minted}


Although subst is a function, in practice it can never be computed.
This is because it works by updating the environment that $P$ refers
to. During symbolic execution, however, the environment is always
abstract, constrained only by the precondition, which means there is
no datastructure to perform updates in. This means that the definition of
\lstinline|subst| that appears in Verifiable C isn't directly useful
to proof automation. It can't compute so without special lemmas and
tactics it will appear in side conditions. To deal with this the Floyd
system has an autorewrite database that lets it push subst through
functions that won't be affected by the substitution. For example

\begin{minted}{coq}
Lemma subst_sepcon: forall i v (P Q: environ->mpred),
  subst i v (P * Q) = (subst i v P * subst i v Q).
\end{minted}

Fortunately, we don't need a lemma for every function that might
appear in assertions. Lifted functions can't do anything with the
environment, they can only pass it on to their arguments, so
by creating autorewrite rules for lifted functions we cover
most of the functions that we use, and also most functions
that a user might want to write. 

Semantic substitution is still inconvenient for a few reasons. First,
the rewrite rules aren't complete. This means that in some cases, after
applying a logic rule, the user will see a \lstinline|subst| in a
resulting condition. This can stop the automated entailment
solvers from working correctly and make the assertion much harder
to read. The next problem is an issue with autorewrite in general.
Autorewrite in Coq is slow. Rewrites aren't known for their 
performance, and autorewrite can do a large number of rewrites
(in the case of \lstinline|subst| the number of rewrites is
linear in the size of the assertion being rewritten). 

There is a situation when a substitution \lstinline|subst $x$ $v$ $P$| can
be avoided completely. That is when $P$ is \emph{closed} wrt. 
$x$, also a semantic notion:

\begin{minted}{coq}
Definition closed_wrt_vars {B} (S: ident -> Prop) (F: environ -> B) : Prop := 
  forall rho te',  
     (forall i, S i \/ Map.get (te_of rho) i = Map.get te' i) ->
     F rho = F (mkEnviron (ge_of rho) (ve_of rho) te').
\end{minted}

Generally we give \lstinline|S| as Coq equality with a specific
identifier.  What \lstinline|closed_wrt_vars| means, then, is that if
\lstinline|F| is supplied an environment that is the same at all
locations but the identifier(s) \lstinline|i| that satisfy
\lstinline|S|, the result of \lstinline|F| will be the same. That
means that if we know \lstinline|closed_wrt_vars (eq x) (e)|, we can
easily prove \lstinline|subst x _ e = e|. More intuitively, if an
expression doesn't contain a variable, a substitution on that variable
won't change the expression.

Floyd has a set lemma that takes advantage of this, stating that if
the precondition and the expression in the assignment are closed wrt
the variable being assigned into, no substitutions are needed, but
there are numerous cases where this rule doesn't apply, so the
substitution will still appear.

\section{Canonical Form}

The reason that substitutions are difficult, and that they need to be
semantic is because there is no \emph{syntactic} restriction on where
any individual identifier can appear within an assertion.  Canonical
form imposes such a restriction, and in doing so, eliminates the need
for semantic substitution, replacing it with a more efficient and
convenient computational syntactic substitution.

One limitation of canonical form is that we no longer allow references
to C program variables in the part of the assertion that contains
spatial assertions. If these assertions wish to talk about those
variables, they must do it indirectly using a Coq variable.  This
means that only the $\LOCAL$ part of the assertion has the ability to
reference local variables. This still doesn't give us the ability to
syntactically locate each reference though, so we restrict $\LOCAL$
further. The restriction we use is to change the entirety of $\LOCAL$
into two computational maps from identifiers to values.  One of these
represents temporary or nonadressable variables, and the other
represents addressable variables. Each mapping represents an equality
between the evaluation of an identifier in the environment, and the
value it maps to. The mappings are represented by PTrees, an efficient
computational data structure in the Coq standard library.

With these two changes we get \emph{canonical form.}  Let
\lstinline{$T_1$: PTree val} be a computational map from C program
identifiers to C values, representing the current values of the
temporary local variables of the current program state. Let
\lstinline{$T_2$: PTree (type*val)} be a map from identifiers to
\lstinline{type*val} representing the addresses of addressable local
variables.  Then \lstinline{localD $T_1$ $T_2$: list(environ->Prop)}
means a list of assertions about the contents of the
\lstinline{environ}, the nonmemory portion of the program state; we do
not need \emph{arbitrary} assertions of type
\lstinline{list(environ->Prop)}.

\lstinline{localD} is a \emph{denotation function}, reflecting the
syntactic (computationally oriented) $T_1$ and $T_2$ back into our
semantic world.  In symbolic execution and efficient entailment
solving, we operate directly on $T_1$ and $T_2$, reflecting the
results back only when the less efficient (but easier to understand)
semantic view is needed by the user. Now a full assertion is:

\begin{lstlisting}
assertD $P$ (localD $T_1$ $T_2$) $R$ : environ->mpred
$P$ : list prop$\qquad$ $T_1$ : PTree val$\qquad$ $T_2$ : PTree (type * val)$\qquad$ $R$ : list mpred
\end{lstlisting}

\subsection{Substitution in Canonical Form}

Substitution in this assertion is as simple as adding/replacing a
mapping in $T_1$ or $T_2$. To see why imagine that we are doing a
substitution on a temporary variable $x$.  \lstinline|$P$ : list prop|
and \lstinline|$R$ : list mpred| don't refer to an environment, so
they are trivially closed wrt.  $x$. This leaves $T_1$ and $T_2$. The
variable $x$ is a temporary variable, so we know $T_2$ is closed
wrt. $x$.  The map $T_1$, however, might have a reference to $x$,
meaning we actually need to do a substitution, making sure to replace
every reference to that variable. One of the requirements of a Coq map
is:

\begin{minted}{coq}
Axiom PTree.gss
     : forall (A : Type) (i : positive) (x : A) (m : PTree.t A),
       PTree.get (PTree.set i x m) i = Some x
\end{minted}

This means that if we update $x$ in some PTree, the old mapping of $x$
will no longer exist, which is the exact definition we want from a
substitution. That is how you do a substitution in an assertion, but
we still need to do substitution in the arbitrary C expression that
appears in the assignment statement and turn that expression into a
value. It is simple enough to turn a C expression into an
\lstinline|environ->val| using the \lstinline|eval_expr| function
discussed in \ref{}, but that expression could have references to
identifiers, which we can't have if we want syntactic
substitution. Instead we can write a different version of
\lstinline|eval_expr| called \lstinline|msubst_eval_expr|. The only
difference between the two functions is that when
\lstinline|msubst_eval_expr| needs to evaluate a variable it doesn't
do it in and environment. Instead, it performs the lookup in PTrees
$T_1$ or $T_2$ mentioned earlier. In other words, if
\lstinline|eval_expr| evaluates an expression in an environment,
\lstinline|msubst_eval_expr| symbolically evaluates an expression in
an assertion. This symbolic evaluation is partial because there might
not be any information about a variable in the assertion. So in our
lemma we require \lstinline|msubst_eval_expr| to succeed:

\begin{lstlisting}
Axiom semax_PTree_set: $~~$forall $\Delta$ id P T1 T2 R $e$ v,
  msubst_eval_expr T1 T2 $e$ = Some v ->
  semax $\Delta$
    (|> local (tc_expr $\Delta$ $e$) && local (tc_temp_id id (typeof e) $\Delta$ e) 
            && (assertD P (localD T1 T2) R))
    (Sset id $e$)
    (normal_ret_assert (assertD P (localD (PTree.set id v T1) T2) R)).
\end{lstlisting}

What that means is that for this lemma to be used, the precondition
must have mappings for every variable that appears in $e$. The
previous lemma didn't require this because it was able to use
\lstinline|eval_expr| wherever it wanted to without requiring a
complete, successful, symbolic execution. This still works for proofs
because \lstinline|`eval_expr $e$| might eventually simplify to
\lstinline|`eval_id $x$|, which could appear in other places in the
assertion.

\lstinline|semax_PTree_set| also doesn't have an existential. This
makes things simpler for the user and the proof automation. The
existential for the old value isn't terribly inconvenient on it's own,
it can be moved to the outside of the triple and introduced without
much difficulty, especially because it's location in the precondition
is consistent. The difficulty comes when choosing what to name the
introduced variable. The solution in the tactics is to allow the user
to specify names with the name tactic. Using \lstinline|name y _y|)
tells the automation that values associated with variable
\lstinline|_y| should automatically be named \lstinline|y| or
\lstinline|y0|, \lstinline|y1|, \ldots if it isn't available.  This is
a decent solution but it puts a hypothesis above the line, adding to
what can already be a long list of hypotheses. It is also inconvenient
in programs that make multiple assignments into the same variable. The
following program is an example of what you might see without improved
tactics or user cleanup:

\begin{minted}{coq}
{`eq (eval_id _x) x}
x = x+1;
{`eq (eval_id _x) (x0 + 1); `eq (x0 x)}
x = x+2;
{`eq (eval_id _x) (x1 + 1); `eq x1 (x0 + 1); `eq x0 x}
...
\end{minted}



Semi-canonical form is very convenient for the user when
\emph{writing} assertions. The list notation is great for combining
assertions without having to remember the exact conjunction that must
be used for each part. It also allows the $\LOCAL$ to remain small,
because if there is a variable the user knows nothing about, there is
no need to add it to the locals. It is less convenient when moving
through a proof of a program. It can introduce existentials and
substitutions that are slow to simplify, or sometimes don't simplify
at all.

Even the current form is not completely canonical. It could be
restricted further which would improve performance in some ways, but
also inconvenience the user in others. Finding a way to sort the
$\SEP$ and keep it sorted as new conjunctions are added could lead to
very efficient and simple entailment solving. This is a harder problem
than sorting the $\LOCAL$ though, because we want $\SEP$ to contain a
variety of predicates, including predicates that are created by the
user. The other problem is that Coq variables can appear as arguments
to the predicates, making it impossible to establish an ordering over
them. Even so, any amount of canonicalization of the $\SEP$ could help
with entailment solving efficiency, so it is worth a look in the
future.

\chapter{Applying A Reflective Framework}

\section{Modular Reflection}

Before presenting the reflective framework we presented both the
typechecker, and a canonical form for assertions which allows us to do
substitutions computationally.  Both our techniques and the reflective
framework are reflective.  They use proved-sound Coq functions to make
progress in a proof. This section discusses how these techniques
interact. There is no interesting interaction between the substitution
and the typechecker because they occur in different places. When we
try to apply a reflective framework to a logic that uses these
reflective techniques, though, we run into some interesting
challenges. This section discusses those challenges and questions if
they are avoidable in a differently designed reflective framework.

A function that is used in a logic can fall into one of three
categories with respect to their interaction with the reflective
framework:

\begin{itemize}
\item A function that operates on constants and returns a type that
  can be represented as a constant requires no modification to be used
  in MirrorCore.
\item A function that operates on constants and returns Prop or Type
  will look exactly the same but return reified results.
\item A function that might operate on Coq variables must take reified
  expressions as arguments and return a reified result.
\end{itemize}

The first category is convenient, but unfortunately fairly few
functions that we use fall into this category. The reason that they
can return any type but Type or Prop is because in general if a
function returns a result we will want to reason about it, and if it
can't be represented by a constant we will be unable to do anything
with it in the Mirror-Core framework.

The second category includes the typechecker which returns
\lstinline|environ -> Prop| that might eventually be discharged by
either the person writing the proof or some automation.  In order to
allow reflective automation to have a chance to solve these remaining
conditions, we must write a new function who instead of returning
\lstinline|environ -> Prop| returns an \lstinline|expr| whose
denotation is (provably) the same as the result of the original
typechecker called on the same arguments.

\begin{minted}{coq}
Definition tc_expr_reif (e : c_expr) (Delta : tycontext) : expr.

Lemma tc_expr_reif_sound_complete : forall tus tvs e Delta,
exprD' tus tvs (tyarr tyenviron typrop) (tc_expr_reif e Delta) =
exprD' tus tbs (tyarr tyenviron typrop) (ftc_expr e Delta).
\end{minted}

Notice that the right hand side of the equality in the lemma doesn't
refer to the original typechecking function but the trivially reified
version. That is, \lstinline|ftc_expr| is a constructor whose
denotation is equal to \lstinline|tc_expr|, while
\lstinline|tc_expr_reif| is a function that when applied will have a
denotation equal to \lstinline|tc_expr| applied to the same
arguments. The function \lstinline|tc_expr_reif| can compute while no
progress can be made on \lstinline|ftc_expr|.  We put the denotation
function on both sides of the function because this allows us to write
an RTac that finds reified terms that look like \lstinline|ftc_expr e Delta|
(uncomputable) and replace them with a term 
\lstinline|tc_expr e Delta|. This is important because we might want to run some other
RTac on the result of the typechecking. Possibly an entailment solver
to discharge any remaining conditions.

We prove that \lstinline|tc_expr_reif| is sound, or that when it has a
denotation, that denotation matches the \lstinline|tc_expr|
function. We also prove it complete by showing that whenever
\lstinline|ftc_expr| has a denotation, \lstinline|tc_expr_reif| does
as well.  In this case sound and complete is the most useful so we
prove it. We have found other cases where only soundness is necessary,
and will discuss those later.

The final category is functions whose inputs might contain Coq
variables. An example of where we run into this is the
\lstinline|PTree.set| and \lstinline|PTree.get| operations that are in
the postcondition of our assignment rules. These functions can be
computed on their own, even if they are given a \lstinline|PTree| with
a coq variable in it as an argument. The problem is that there is no
way to represent any datastructure that contains a coq variable as a
constant. This is because there is no way to computationally compare
two Coq variables for equality. In order to computationally check
equality over Coq variables, they must first be reified.  Reification
is designed so that if it sees the same variable twice, it will use
the same constructor to represent both instances. The constructors can
be computationally compared, so variables can be compared in reified
syntax.  We will need to do comparisons on the variables in the local
assertion almost any time we solve an entailment, so we will need to
reify the variables.

What that means is that we must rewrite \lstinline|PTree.set| and
\lstinline|PTree.get| to operate on fully reified PTrees. This can be
difficult because of the size of the reified syntax. One way to
mitigate the complexity of the code is to create a function that
matches a reified expression as a tree:

\begin{minted}{coq}
Definition as_tree (e : expr typ func) : option
  ((typ * expr typ func * expr typ func * expr typ func) + typ) := 
match e with
  | (App (App (App (Inj (inr (Data (fnode t)))) l) o) r) =>
    Some (inl (t, l, o, r))
  | (Inj (inr (Data (fleaf t)))) =>
    Some (inr t)
  | _ => None
end.
\end{minted}

This allows the function that operates over reified expressions to look very
similar to original expression, and also simplifies the proof. The function
and the proof will now have 3 cases. The first have the same behavior (only reified)
as the \lstinline|leaf| and \lstinline|node| cases of the original function. The third
case is the case where \lstinline|as_tree| returns \lstinline|None|. This doesn't
mean that the function doesn't typecheck because there is no requirement on 
expressions that a PTree can only be represented by those two constructors. There
could be another constructor with the same denotation, or more likely a PTree
could be an application of \lstinline|PTree.set| that didn't get simplified.
If we encounter a reified PTree that isn't represented
only by the expected constructors, we have a choice depending on
weather we require completeness or not. If we require completeness,
we can just apply the set function as a reified constructor. This
will result in a complete function. That means that if we
pass our reified function all valid reified arguments
the denotation of the result of the function will always
match the denotation of the original function applied
to the denotation of the arguments. It is the most convenient
to write an RTac for reified functions of this type because
there is a pre-built RTac that replaces one reified expression
with another. This RTac can only be proved sound if there is a proof
of equality between any two expressions that the tactic might come
across. The only downside to this approach is that proving that the
reified function is complete takes much more work than only proving it
sound. 

These reified functions are an inconvenience and one of the largest
barriers to easily applying a reflective framework in a setting like
VST. It is an important open question weather this is avoidable. Can
a reflective framework reuse computations that might operate
over Coq variables without requiring reified functions? 

\chapter{Evaluation}

We combine the steps of reification, computation, and reflection
together with an application of the soundness proof of Rtac and our
symbolic execution function to create the \lstinline|rforward|, or
reflective forward, tactic that can operate directly on Coq proof
goals. Because it operates on proof goals, \lstinline|rforward| must
be programmed in Ltac.  It works by:
\begin{enumerate}
\item calling MirrorCore's Ocaml plugin to reify the goal,
\item calling \lstinline|vm_compute| on the symbolic execution Rtac
  applied to the reified goal,
\item applying the soundness lemma for the symbolic execution Rtac
  using the reified goal and the Rtac result as arguments, and
\item taking the denotation of the remaining subgoals.
\end{enumerate}
The key to making proof by reflection efficient is the use of the
\lstinline|vm_compute| tactic, which compiles bytecode and runs it in
a bytecode interpreter. The \lstinline|vm_compute| tactic is the
fastest way to do evaluation ($\beta\eta\delta$-normalization) in Coq
8.4; we expect the forthcoming \lstinline{native_compute} of Coq 8.5
will improve \emph{all} the results in this paper even more.  The use
of \lstinline|vm_compute| can do more harm than good in the wrong
situations. Calling it on subgoals with opaque variables can stop
functions from simplifying. If this happens deep in a stack of
function calls, resulting terms can become massive, and evaluation can
take an extremely long time. Therefore it is important to call
\lstinline|vm_compute| only on expressions that definitely evaluate to
a reasonably sized result. The reasonably sized result must assume
that all definitions that appear in the original expression will be
unfolded completely, meaning that there shouldn't be opaque terms
anywhere in a term VM compute is run on.

  
The test we present here is the symbolic execution of a program with
$n$ statements that assigns $0$ into $n$ different variables. This
test is actually a best case for the Ltac version because it is able
to notice that the precondition is always closed w.r.t the variable we
are assigning into and avoid introducing an existential at each
step. 
We show the performance of Ltac and
Rtac as $n$ increases in Figure \ref{fig:chart}.

\begin{figure}
\vspace{-2ex}
\includegraphics[width=\textwidth]{chart.pdf}
\vspace{-4ex}
\caption{Run time of Ltac vs Rtac, for $n$ consecutive C statements (log-log scale).}
\label{fig:chart}
\vspace{-4ex}
\end{figure}

Each data point is the average of 10 consecutive runs on a standard laptop. The
amount of memory on the laptop is over 2 gigabytes, which is the
maximum amount of memory that 32-bit Coq can use. Because it is very
difficult to get 64-bit Coq on all platforms, we attempt to write
tactics that can operate within the lower memory bounds.

Although this is a synthetic test, we consider
it a lower bound on the performance increase we will see in the
process of a real proof. This is because numerous other tests
indicate that for non-addressed variable assignments the size of the
precondition has the predominant effect on the run-time, not the
contents. This follows from what we would expect. The computation that
we need to do is almost all getting and setting from efficient tree
maps where get and set take $\log(n)$ time where $n$ is the largest
index that exists in the map. This is acceptable because we know that
our program input will be compiled by CompCert, and CompCert always
starts its variable indices with $1$, moving up sequentially. We can
be confident that this will always be the case because CompCert makes
use of PTrees. The remainder of the operations that RTac does are
linear (or slower) unifications between lemmas and proof goals, as
well as linear (or slower) rewrites by proved equalities. Repeated
linear operations are what lead to the polynomial operation we observe in
the chart above, not repeated $\log(n)$ gets and sets. 

The chart shows that there 
is a speedup of (typically) 40$\times$ (e.g., running $n\! = \! 8$ consecutive
C-program statements). 
Speedup improves with scale: $n\! =\! 50$ 
steps in Ltac takes over 2 minutes, while
the same number of steps in Rtac takes only .9 seconds, running almost 150$\times$ faster! 
Even for $n\!=\!1$ there is a 4$\times$ speedup.
This greatly improves interactivity of the logic. In general it
seems that growth of time relative to the number of program steps is
quadratic. Our benchmark that uses more complex preconditions
scales even better (not shown in a graph),
with 74$\times$ speedup at $n\! = \!10$.


The \emph{computation} curve, at the upper end, clearly
shows a time complexity of $n^{2.5}$.
This time complexity is roughly what we expect,
because (in this example) the
precondition grows linearly with the number of steps,
and each step has proof operations at least proportional to the size
of the precondition.



On a real-life example, a loop-body from 
OpenSSL's SHA function\footnote{The second loop body in
the \lstinline{sha256_block_data_order} function of the cited paper \cite{appel15:sha}; there are 850 nodes in the loop body's abstract synax tree.} 
takes 336 seconds to verify in our Ltac \lstinline{forward} tactic;
\lstinline|rforward| takes only 12 seconds---a 28$\times$ speedup. The sequence
includes 13 local-variable assignments,
5 loads, and 1 store, several of which contain 
huge mathematical expressions (resulting from macro-expansion in the
C source code). The assertions in that example
are large, with many local-variable and
spatial conjuncts.

Our computational theory of nested records yields 
a significant performance improvement.
Our \lstinline{data_at} benchmark verifies a sequence of 
4 loads and 4 stores
on a data structure represented by 8 spatial conjuncts,
taking 63 seconds in Ltac.  Using 
\lstinline{data_at}, with just one conjunct, 
verification takes 15 seconds in Ltac, a factor of 4 improvement.
We don't expect to see the same speedup in Rtac, which in
general is slower to be affected by changes in precondition size.

Unfortunately, after Rtac has efficiently computed a proof,
Coq's \lstinline|Qed| blows up, taking minutes  in some cases.
Qed blowups tend to occur when Coq cannot find an efficient
$\beta\eta$-conversion sequence to prove an equality
(even if the tactic script demonstrated one).
In the next section we discuss how to fix this.
Performance measurements in this section (for both Ltac and Rtac)
do not include Qed times; the Ltac Qed times are larger than
the Rtac Qed times, but both are terrible (e.g., 815 and 615 seconds,
respectively, for the SHA loop-body example).

While this is frustrating, as Coq continues to mature, even if Qed
time is slow, it won't cause too much frustration to the user. This is
because starting with Coq 8.5, proofs can be built and checked
asynchronously, allowing their statements to be used farther down in a
file while they build. A Qed time of a few minutes is inconsequential
as long as the user doesn't need to wait for it to continue proofs,
even proofs using the not-yet-checked proof. Furthermore, Coq 8.5 will allow for Coq .v
files to be compiled without checking proofs, making them very quickly
importable. Later it is possible to replace the unchecked object files
with object files. This means that libraries that are slow to build
can be built and usable rapidly, and then the actual work of checking
the proofs can be done in the background at the user's convenience.

\chapter{Conclusion}

\bibliographystyle{plain}
\bibliography{appel.bib}

\end{document}

